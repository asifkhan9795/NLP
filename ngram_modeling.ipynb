{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QayCkL6okctz",
        "outputId": "e94a2fa3-2f46-49d2-e051-0ab0a3b83bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigrams Frequency Distribution:\n",
            "('i', 'want'): 1\n",
            "('want', 'to'): 1\n",
            "('to', 'travel'): 1\n",
            "('travel', 'world'): 1\n",
            "('world', 'i'): 1\n",
            "('i', 'am'): 3\n",
            "('am', 'a'): 1\n",
            "('a', 'good'): 1\n",
            "('good', 'data'): 1\n",
            "('data', 'scientist'): 1\n",
            "('scientist', 'python'): 1\n",
            "('python', 'is'): 1\n",
            "('is', 'a'): 1\n",
            "('a', 'great'): 1\n",
            "('great', 'tool'): 1\n",
            "('tool', 'for'): 1\n",
            "('for', 'data'): 1\n",
            "('data', 'science'): 1\n",
            "('science', 'learning'): 1\n",
            "('learning', 'nlp'): 2\n",
            "('nlp', 'is'): 3\n",
            "('is', 'challenging'): 2\n",
            "('challenging', 'pleasant'): 1\n",
            "('pleasant', 'weather'): 1\n",
            "('weather', 'while'): 1\n",
            "('while', 'traveling'): 1\n",
            "('traveling', 'islamabad'): 1\n",
            "('islamabad', 'nlp'): 1\n",
            "('is', 'fun'): 1\n",
            "('fun', 'i'): 1\n",
            "('i', 'can'): 1\n",
            "('can', 'do'): 1\n",
            "('do', 'it'): 1\n",
            "('it', 'i'): 1\n",
            "('i', 'dont'): 1\n",
            "('dont', 'know'): 1\n",
            "('know', 'and'): 1\n",
            "('and', 'please'): 1\n",
            "('please', 'do'): 1\n",
            "('do', \"n't\"): 1\n",
            "(\"n't\", 'tell'): 1\n",
            "('tell', 'me'): 1\n",
            "('me', 'what'): 1\n",
            "('what', 'is'): 1\n",
            "('is', 'your'): 1\n",
            "('your', 'name'): 1\n",
            "('name', 'i'): 1\n",
            "('i', 'think'): 1\n",
            "('think', 'learning'): 1\n",
            "('challenging', 'i'): 1\n",
            "('am', 'enjoing'): 1\n",
            "('enjoing', 'i'): 1\n",
            "('i', 'like'): 2\n",
            "('like', 'to'): 2\n",
            "('to', 'ride'): 1\n",
            "('ride', 'a'): 1\n",
            "('a', 'bicycle'): 1\n",
            "('bicycle', 'in'): 1\n",
            "('in', 'the'): 1\n",
            "('the', 'morning'): 1\n",
            "('morning', 'i'): 1\n",
            "('to', 'walk'): 1\n",
            "('walk', 'in'): 1\n",
            "('in', 'evvening'): 1\n",
            "('evvening', 'i'): 1\n",
            "('am', 'learning'): 1\n",
            "('learning', 'new'): 1\n",
            "('new', 'habits'): 1\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import bigrams\n",
        "from nltk.probability import FreqDist, ConditionalFreqDist\n",
        "\n",
        "# Sample sentences\n",
        "sentences = [\n",
        "    \"I love programming in Python\",\n",
        "    \"I love programming in Python\",\n",
        "    \"I love programming in Python\",\n",
        "    \"I love programming in Python\",\n",
        "    \"Python is great for data science\",\n",
        "    \"I enjoy learning new algorithms\",\n",
        "    \"Algorithms are the backbone of computer science\",\n",
        "    \"Data science involves statistics and coding\",\n",
        "    \"Coding is a valuable skill\",\n",
        "    \"I love solving problems with code\",\n",
        "    \"Machine learning is fascinating\",\n",
        "    \"Natural language processing is a part of AI\",\n",
        "    \"AI is transforming the world\"\n",
        "]\n",
        "\n",
        "sentences = [\"i want to travel world\",\n",
        "\"I am a good data scientist\"\n",
        ",\n",
        "\"python is a great tool for data science\"\n",
        ",\n",
        "\"learning NLP is challenging\"\n",
        ",\n",
        "\"pleasant weather while traveling Islamabad\"\n",
        ",\n",
        "\"NLP is fun\"\n",
        ",\n",
        "\"<s>i can do it</s></s>\"\n",
        ",\n",
        "\"I dont know and please don't tell me what is your name\"\n",
        ",\n",
        "\"I think learning NLP is challenging\",\"i am enjoing\", \"i like to ride a bicycle in the morning\",\"I like to walk in evvening\", \"i am learning new habits\"]\n",
        "\n",
        "# Tokenizing sentences into words\n",
        "tokens = [nltk.word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "flat_tokens = [item for sublist in tokens for item in sublist]\n",
        "\n",
        "# Generating bigrams\n",
        "bigrams_list = list(bigrams(flat_tokens))\n",
        "\n",
        "# Frequency distributions\n",
        "bigram_freq = FreqDist(bigrams_list)\n",
        "conditional_freq = ConditionalFreqDist(bigrams_list)\n",
        "\n",
        "# Displaying results\n",
        "print(\"Bigrams Frequency Distribution:\")\n",
        "for bigram, freq in bigram_freq.items():\n",
        "    print(f\"{bigram}: {freq}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[12345\n",
        " 12345\n",
        " 12345]"
      ],
      "metadata": {
        "id": "XP8PWTQB5JZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRaX4sBkku_S",
        "outputId": "6670fd2a-b0ef-4c69-8ff9-c9aff11cc61f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import bigrams\n",
        "from nltk.probability import FreqDist, ConditionalFreqDist\n",
        "\n",
        "# Sample sentences\n",
        "# sentences = [\n",
        "#     \"I love programming in Python\",\n",
        "#     \"Python is great for data science\",\n",
        "#     \"I enjoy learning new algorithms\",\n",
        "#     \"Algorithms are the backbone of computer science\",\n",
        "#     \"Data science involves statistics and coding\",\n",
        "#     \"Coding is a valuable skill\",\n",
        "#     \"I love solving problems with code\",\n",
        "#     \"Machine learning is fascinating\",\n",
        "#     \"Natural language processing is a part of AI\",\n",
        "#     \"AI is transforming the world\"\n",
        "# ]\n",
        "\n",
        "# Tokenizing sentences into words\n",
        "tokens = [nltk.word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "flat_tokens = [item for sublist in tokens for item in sublist]\n",
        "\n",
        "# Generating bigrams\n",
        "bigrams_list = list(bigrams(flat_tokens))\n",
        "\n",
        "# Frequency distributions\n",
        "bigram_freq = FreqDist(bigrams_list)\n",
        "conditional_freq = ConditionalFreqDist(bigrams_list)\n",
        "\n",
        "# Function to predict the next token\n",
        "def predict_next_token(word):\n",
        "    word = word.lower()\n",
        "    if word in conditional_freq:\n",
        "        next_tokens = conditional_freq[word].most_common(3)  # Get top 3 predictions\n",
        "        return [token for token, freq in next_tokens]\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "# Input for prediction\n",
        "input_word = input(\"Enter a word to predict the next token: \")\n",
        "predicted_tokens = predict_next_token(input_word)\n",
        "\n",
        "# Displaying results\n",
        "if predicted_tokens:\n",
        "    print(f\"Predicted next tokens for '{input_word}': {predicted_tokens}\")\n",
        "else:\n",
        "    print(f\"No predictions available for '{input_word}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flEutbxTksil",
        "outputId": "87a71ffc-a283-4cae-deb1-1986ad3d3dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a word to predict the next token: in\n",
            "Predicted next tokens for 'in': ['the', 'evvening']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I am a good data scientist python is challenging\n",
        "# I want to walk in evvening"
      ],
      "metadata": {
        "id": "q285D8Zc8qqZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}